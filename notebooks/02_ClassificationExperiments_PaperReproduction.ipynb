{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments - Paper Reproduction\n",
    "\n",
    "The goal of this notebook is reproducing the results from the paper [Building a Sentiment Corpus of Tweets in Brazilian Portuguese](https://arxiv.org/abs/1712.08917).\n",
    "\n",
    "According to the publication, the steps performed were:\n",
    " - Data Representation:\n",
    "     - Bag-of-words with occurrence of terms\n",
    "     - Presence of negation words (‚Äúnot‚Äù, ‚Äúnever‚Äù,...) (Avan√ßo et al., 2016)\n",
    "     - Positive and negative emoticons (Avan√ßo et al., 2016)\n",
    "     - Positive and negative emojis (Avan√ßo et al., 2016)\n",
    "     - Presence of positive and negative words (Avan√ßo et al., 2016)\n",
    "     - PoS tags (NLPnet tagger (Fonseca et al., 2015))\n",
    " - Algorithms:\n",
    "    - Linear SVM (C: 1)\n",
    "    - Bernoulli Naive Bayes (alpha:0.1)\n",
    "    - Logistic Regression\n",
    "    - Multilayer Perceptron (2 layers, 200 neurons, learning-rate:00.1)\n",
    "    - Decision Tree classifier\n",
    "    - Random Forest approach with 200 estimators.\n",
    "\n",
    "## Libraries and Settings\n",
    "\n",
    "Load basic libraries and append source code directory (src) into the system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdy party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import funcy as fp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# Visualization / Presentation\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "# NLP Libraries\n",
    "import re\n",
    "import nlpnet\n",
    "import stanza\n",
    "import spacy\n",
    "from spacy.tokenizer import _get_regex_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import settings\n",
    "from src.pipeline.resources import load_corpus\n",
    "from src.pipeline.general import clean_text\n",
    "from src.pipeline.executors import simple_pipeline_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "pd.set_option('max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>votes</th>\n",
       "      <th>hard</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>group</th>\n",
       "      <th>text</th>\n",
       "      <th>repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>863044774588272640</td>\n",
       "      <td>#encontro</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>que coisa linda O programa estava mostrando uma familia que adotou um adolescente de NUMBER anos que amor !</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>865583716088766467</td>\n",
       "      <td>#encontro</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>por mais com as irm√£s galv√£o adorei elas</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>865063232201011201</td>\n",
       "      <td>#TheNoite</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mr CATRA USERNAME lan√ßando sua nova m√∫sica PPK CHORA no USERNAME k k k üëÖ üòâ #MrCatra #PpkChora</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864668391008763905</td>\n",
       "      <td>#masterchefbr</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>quem viu aquela lutadora modela barbuda tatuada #MasterChefBR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>865572794016378882</td>\n",
       "      <td>#encontro</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1]</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>test</td>\n",
       "      <td>t√¥ passada com esse cara quanta merda pode sair da boca de algu√©m em alguns minutos üò†</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        hashtag                         votes hard  \\\n",
       "0  863044774588272640      #encontro         [1, 1, 1, 1, 1, 1, 1]    0   \n",
       "1  865583716088766467      #encontro         [1, 1, 1, 1, 1, 1, 1]    0   \n",
       "2  865063232201011201      #TheNoite         [1, 0, 1, 1, 1, 0, 0]    2   \n",
       "3  864668391008763905  #masterchefbr         [0, 0, 0, 0, 0, 0, 0]    0   \n",
       "4  865572794016378882      #encontro  [-1, -1, -1, -1, -1, -1, -1]    0   \n",
       "\n",
       "  sentiment group  \\\n",
       "0         1  test   \n",
       "1         1  test   \n",
       "2         1  test   \n",
       "3         0  test   \n",
       "4        -1  test   \n",
       "\n",
       "                                                                                                          text  \\\n",
       "0  que coisa linda O programa estava mostrando uma familia que adotou um adolescente de NUMBER anos que amor !   \n",
       "1                                                                     por mais com as irm√£s galv√£o adorei elas   \n",
       "2                mr CATRA USERNAME lan√ßando sua nova m√∫sica PPK CHORA no USERNAME k k k üëÖ üòâ #MrCatra #PpkChora   \n",
       "3                                                quem viu aquela lutadora modela barbuda tatuada #MasterChefBR   \n",
       "4                        t√¥ passada com esse cara quanta merda pode sair da boca de algu√©m em alguns minutos üò†   \n",
       "\n",
       "   repeat  \n",
       "0   False  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = load_corpus()\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate training and test records and delete the original frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = frame.loc[(frame.group == 'train') & (frame.sentiment.isin(['-1', '0', '1']))].copy(deep=True)\n",
    "test = frame.loc[(frame.group == 'test') & (frame.sentiment.isin(['-1', '0', '1']))].copy(deep=True)\n",
    "del frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check class balance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     5741\n",
       "-1    3839\n",
       "0     3410\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Extract Features from Tweets\n",
    "\n",
    "Instantiate NLP libraries to tokenize text and extract information (e.g., lemma, pos tag, and polarization).\n",
    "\n",
    "There are three libraries used:\n",
    " - [nlpnet](http://nilc.icmc.usp.br/nlpnet/): Used to be able to reproduce exactly the same pos tags used by TweetSentBR.\n",
    " - [Spacy](https://spacy.io/): Lightweight and versatile library to perform tokenization, and get lemma and pos tags.\n",
    " - [Stanza](https://stanfordnlp.github.io/stanza/): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpnet.set_data_dir(settings.NLPNET_POS_TAGGER_PATH)\n",
    "nlpnet_nlp = nlpnet.POSTagger().tag\n",
    "\n",
    "# Load Stanza to get access to tokenization, words expansion, pos tags, lemmas and polarization\n",
    "stanza_nlp = stanza.Pipeline('pt', processors='tokenize, mwt, pos, lemma', use_gpu=False, tokenize_no_ssplit=True, verbose=0)\n",
    "\n",
    "# Load Spacy to get access tokenization, lemma and pos tag\n",
    "spacy_nlp = spacy.load('pt')\n",
    "\n",
    "# Extend default token regex to avoid splitting hashtag, smile, emoji and emoticon.\n",
    "re_token_match = _get_regex_pattern(spacy_nlp.Defaults.token_match)\n",
    "re_token_match = f\"({re_token_match}|#\\w+|\\w+-\\w+)\"\n",
    "spacy_nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over tweets to trim repeating spaces and words with more than 2 contiguous characters repeated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_clean_text = partial(clean_text, unify_html_tags=False, unify_urls=False, trim_repeating_spaces=True, unify_hashtags=False,\n",
    "                             unify_mentions=False, unify_numbers=False, trim_repeating_letters=True)\n",
    "\n",
    "training.loc[:, 'clean_text'] = training['text'].apply(partial_clean_text)\n",
    "test.loc[:, 'clean_text'] = test['text'].apply(partial_clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records changed: 1,510 from 12,990 (11.62%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>votes</th>\n",
       "      <th>hard</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>group</th>\n",
       "      <th>text</th>\n",
       "      <th>repeat</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>864531050508288000</td>\n",
       "      <td>#videoShowAoVivo</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>sofia linda esse seu batom t√° show e joaquim como sempre lindo bjusss da paraiba</td>\n",
       "      <td>False</td>\n",
       "      <td>sofia linda esse seu batom t√° show e joaquim como sempre lindo bjuss da paraiba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>864301806544990208</td>\n",
       "      <td>#maisvoce</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>USERNAME coitada da ta√≠s ara√∫jo ! üç≤ üòÇ üòÇ üòÇ üç≤ kkkk #MaisVoc√™</td>\n",
       "      <td>False</td>\n",
       "      <td>USERNAME coitada da ta√≠s ara√∫jo ! üç≤ üòÇ üòÇ üòÇ üç≤ kk #MaisVoc√™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>865426213510053889</td>\n",
       "      <td>#ConversaComBial</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>ahhh vai come√ßar uhuuu üòç üòç üëè üèº üëè üèº üëè üèº üëè üèº üëè üèº üíú üíú USERNAME #MaiaraeMaraisaNoBial</td>\n",
       "      <td>False</td>\n",
       "      <td>ahh vai come√ßar uhuu üòç üòç üëè üèº üëè üèº üëè üèº üëè üèº üëè üèº üíú üíú USERNAME #MaiaraeMaraisaNoBial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>865059540303310848</td>\n",
       "      <td>#TheNoite</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>o mestre mandou √© o melhor quadro velho kkk</td>\n",
       "      <td>False</td>\n",
       "      <td>o mestre mandou √© o melhor quadro velho kk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>864335520167362560</td>\n",
       "      <td>#TheNoite</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>hist√≥ria b√™bada do USERNAME hj kkk</td>\n",
       "      <td>False</td>\n",
       "      <td>hist√≥ria b√™bada do USERNAME hj kk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>864889627232141314</td>\n",
       "      <td>#videoShowAoVivo</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>outra coisa jocaota tem brilho tem gra√ßa amooo</td>\n",
       "      <td>False</td>\n",
       "      <td>outra coisa jocaota tem brilho tem gra√ßa amoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>864334590353195008</td>\n",
       "      <td>#TheNoite</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>MINHA SERIEEE</td>\n",
       "      <td>False</td>\n",
       "      <td>MINHA SERIEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>864467549215436805</td>\n",
       "      <td>#maisvoce</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>pra me ganhar de vez VIAVIANE FAZ PLANILHAS √â NERD ESTUDAAA ATRIZ DE VERDADE SE ORGANIZA pasmanterepivanomaisvoce</td>\n",
       "      <td>False</td>\n",
       "      <td>pra me ganhar de vez VIAVIANE FAZ PLANILHAS √â NERD ESTUDAA ATRIZ DE VERDADE SE ORGANIZA pasmanterepivanomaisvoce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>862156481885601793</td>\n",
       "      <td>#masterchefbr</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>ahhh uma semana pra ter de novo :(</td>\n",
       "      <td>False</td>\n",
       "      <td>ahh uma semana pra ter de novo :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>864685396357242880</td>\n",
       "      <td>#masterchefbr</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>A paola kkk</td>\n",
       "      <td>False</td>\n",
       "      <td>A paola kk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id           hashtag votes hard sentiment  group  \\\n",
       "301  864531050508288000  #videoShowAoVivo   [1]    0         1  train   \n",
       "318  864301806544990208         #maisvoce  [-1]    0        -1  train   \n",
       "323  865426213510053889  #ConversaComBial   [1]    0         1  train   \n",
       "324  865059540303310848         #TheNoite   [1]    0         1  train   \n",
       "335  864335520167362560         #TheNoite   [1]    0         1  train   \n",
       "338  864889627232141314  #videoShowAoVivo   [1]    0         1  train   \n",
       "348  864334590353195008         #TheNoite   [1]    0         1  train   \n",
       "372  864467549215436805         #maisvoce   [1]    0         1  train   \n",
       "393  862156481885601793     #masterchefbr  [-1]    0        -1  train   \n",
       "401  864685396357242880     #masterchefbr  [-1]    0        -1  train   \n",
       "\n",
       "                                                                                                                  text  \\\n",
       "301                                   sofia linda esse seu batom t√° show e joaquim como sempre lindo bjusss da paraiba   \n",
       "318                                                         USERNAME coitada da ta√≠s ara√∫jo ! üç≤ üòÇ üòÇ üòÇ üç≤ kkkk #MaisVoc√™   \n",
       "323                                  ahhh vai come√ßar uhuuu üòç üòç üëè üèº üëè üèº üëè üèº üëè üèº üëè üèº üíú üíú USERNAME #MaiaraeMaraisaNoBial   \n",
       "324                                                                        o mestre mandou √© o melhor quadro velho kkk   \n",
       "335                                                                                 hist√≥ria b√™bada do USERNAME hj kkk   \n",
       "338                                                                     outra coisa jocaota tem brilho tem gra√ßa amooo   \n",
       "348                                                                                                      MINHA SERIEEE   \n",
       "372  pra me ganhar de vez VIAVIANE FAZ PLANILHAS √â NERD ESTUDAAA ATRIZ DE VERDADE SE ORGANIZA pasmanterepivanomaisvoce   \n",
       "393                                                                                 ahhh uma semana pra ter de novo :(   \n",
       "401                                                                                                        A paola kkk   \n",
       "\n",
       "     repeat  \\\n",
       "301   False   \n",
       "318   False   \n",
       "323   False   \n",
       "324   False   \n",
       "335   False   \n",
       "338   False   \n",
       "348   False   \n",
       "372   False   \n",
       "393   False   \n",
       "401   False   \n",
       "\n",
       "                                                                                                           clean_text  \n",
       "301                                   sofia linda esse seu batom t√° show e joaquim como sempre lindo bjuss da paraiba  \n",
       "318                                                          USERNAME coitada da ta√≠s ara√∫jo ! üç≤ üòÇ üòÇ üòÇ üç≤ kk #MaisVoc√™  \n",
       "323                                   ahh vai come√ßar uhuu üòç üòç üëè üèº üëè üèº üëè üèº üëè üèº üëè üèº üíú üíú USERNAME #MaiaraeMaraisaNoBial  \n",
       "324                                                                        o mestre mandou √© o melhor quadro velho kk  \n",
       "335                                                                                 hist√≥ria b√™bada do USERNAME hj kk  \n",
       "338                                                                     outra coisa jocaota tem brilho tem gra√ßa amoo  \n",
       "348                                                                                                      MINHA SERIEE  \n",
       "372  pra me ganhar de vez VIAVIANE FAZ PLANILHAS √â NERD ESTUDAA ATRIZ DE VERDADE SE ORGANIZA pasmanterepivanomaisvoce  \n",
       "393                                                                                 ahh uma semana pra ter de novo :(  \n",
       "401                                                                                                        A paola kk  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disposable_frame = training.query('text != clean_text')\n",
    "print(f'Records changed: {len(disposable_frame):,} from {len(training):,} ({len(disposable_frame) / len(training) * 100:.2f}%)')\n",
    "display(disposable_frame.head(10))\n",
    "del disposable_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and extract features from sentences and tokens on both, training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bruno/f331903b-17cb-447b-b132-e6f1f08f80f8/Development/02_TwitterBR_SentimentAnalysis/pt_br_tweets_sentiment_analysis/src/pipeline/computers.py:45: RuntimeWarning: invalid value encountered in true_divide\n",
      "  polarities_percentage = polarities_count / total\n",
      "/media/bruno/f331903b-17cb-447b-b132-e6f1f08f80f8/Development/02_TwitterBR_SentimentAnalysis/pt_br_tweets_sentiment_analysis/src/pipeline/computers.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  polarities_percentage = polarities_count / total\n",
      "/media/bruno/f331903b-17cb-447b-b132-e6f1f08f80f8/Development/02_TwitterBR_SentimentAnalysis/venv/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "from src.pipeline.processors import *\n",
    "from src.pipeline.computers import *\n",
    "from src.pipeline.extractors import *\n",
    "\n",
    "main_word_processors = [#process_word_polarity, process_word_pos_tag,\n",
    "                         process_negative_words, process_sentilex_word_polarity, process_emoticon_polarity, process_emoji_polarity]\n",
    "main_sentence_processors = [#compute_polarity_features, compute_pos_tag_features,\n",
    "                             compute_negative_words_features, compute_sentilex_polarity_features, compute_emoticon_polarity_features, compute_emoji_polarity_features]\n",
    "\n",
    "training[['tokens', 'features']] = simple_pipeline_executor(training.clean_text.tolist(), extract_tokens_and_features, spacy_nlp, main_word_processors, main_sentence_processors)\n",
    "test[['tokens', 'features']] = simple_pipeline_executor(test.clean_text.tolist(), extract_tokens_and_features, spacy_nlp, main_word_processors, main_sentence_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use nlpnet to extract pos tags from tokens and create additional features from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_word_processors = [#process_word_polarity, \n",
    "                        process_word_pos_tag]\n",
    "extra_sentence_processors = [#compute_polarity_features, \n",
    "                            compute_pos_tag_features]\n",
    "\n",
    "training['pos_tag_features'] = simple_pipeline_executor(training.clean_text.tolist(), extract_features, nlpnet_nlp, extra_word_processors, extra_sentence_processors)\n",
    "test['pos_tag_features'] = simple_pipeline_executor(test.clean_text.tolist(), extract_features, nlpnet_nlp, extra_word_processors, extra_sentence_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert there are no *NA* values on features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['features', 'aux_features', 'pos_tag_features']:\n",
    "    if column in training.columns:\n",
    "        X = training[column].to_numpy()\n",
    "        X = np.stack(X, axis=0)\n",
    "        assert all([len(item) == 0 for item in np.where(np.isnan(X))]), f'There are na values in {column} column.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>votes</th>\n",
       "      <th>hard</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>group</th>\n",
       "      <th>text</th>\n",
       "      <th>repeat</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>features</th>\n",
       "      <th>pos_tag_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>863587647016636417</td>\n",
       "      <td>#altasHoras</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>apareceu o √≠ndice de morte na minha cidade t√¥ muito assustado #BelemPedePaz</td>\n",
       "      <td>False</td>\n",
       "      <td>apareceu o √≠ndice de morte na minha cidade t√¥ muito assustado #BelemPedePaz</td>\n",
       "      <td>[aparecer, o, √≠ndice, de, morte, o, meu, cidade, t√¥, muito, assustar, #BelemPedePaz]</td>\n",
       "      <td>[0, 2, 10, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>863591661594697728</td>\n",
       "      <td>#altasHoras</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>O tchan j√° pode substituir a morena pela bella gil #AltasHoras</td>\n",
       "      <td>False</td>\n",
       "      <td>O tchan j√° pode substituir a morena pela bella gil #AltasHoras</td>\n",
       "      <td>[O, tchan, j√°, poder, substituir, o, moreno, pelar, bella, gil, #AltasHoras]</td>\n",
       "      <td>[0, 0, 11, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>863385491344941060</td>\n",
       "      <td>#√©decasa</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>rafael ainda nem nasceu e j√° escuta USERNAME #anjo #40semanas #EDeCasa</td>\n",
       "      <td>False</td>\n",
       "      <td>rafael ainda nem nasceu e j√° escuta USERNAME #anjo #40semanas #EDeCasa</td>\n",
       "      <td>[rafael, ainda, nem, nascer, e, j√°, escutar, USERNAME, #anjo, #40semanas, #EDeCasa]</td>\n",
       "      <td>[1, 0, 11, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>865073884411953152</td>\n",
       "      <td>#ConversaComBial</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>at√© que enfim um excelente programa de entrevistas na TV aberta üëç</td>\n",
       "      <td>False</td>\n",
       "      <td>at√© que enfim um excelente programa de entrevistas na TV aberta üëç</td>\n",
       "      <td>[at√©, que, enfim, um, excelente, programar, de, entrevisto, o, TV, aberto, üëç]</td>\n",
       "      <td>[0, 0, 10, 2, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>862176233949409281</td>\n",
       "      <td>#masterchefbr</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>master chef me da fome de madrugadato virando coruja sonambulo</td>\n",
       "      <td>False</td>\n",
       "      <td>master chef me da fome de madrugadato virando coruja sonambulo</td>\n",
       "      <td>[master, chef, me, da, fome, de, madrugadato, virar, corujar, sonambulo]</td>\n",
       "      <td>[0, 1, 9, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id           hashtag votes hard sentiment  group  \\\n",
       "283  863587647016636417       #altasHoras  [-1]    0        -1  train   \n",
       "284  863591661594697728       #altasHoras   [0]    0         0  train   \n",
       "285  863385491344941060          #√©decasa   [1]    0         1  train   \n",
       "286  865073884411953152  #ConversaComBial   [1]    0         1  train   \n",
       "287  862176233949409281     #masterchefbr   [1]    0         1  train   \n",
       "\n",
       "                                                                            text  \\\n",
       "283  apareceu o √≠ndice de morte na minha cidade t√¥ muito assustado #BelemPedePaz   \n",
       "284               O tchan j√° pode substituir a morena pela bella gil #AltasHoras   \n",
       "285       rafael ainda nem nasceu e j√° escuta USERNAME #anjo #40semanas #EDeCasa   \n",
       "286            at√© que enfim um excelente programa de entrevistas na TV aberta üëç   \n",
       "287               master chef me da fome de madrugadato virando coruja sonambulo   \n",
       "\n",
       "     repeat  \\\n",
       "283   False   \n",
       "284   False   \n",
       "285   False   \n",
       "286   False   \n",
       "287   False   \n",
       "\n",
       "                                                                      clean_text  \\\n",
       "283  apareceu o √≠ndice de morte na minha cidade t√¥ muito assustado #BelemPedePaz   \n",
       "284               O tchan j√° pode substituir a morena pela bella gil #AltasHoras   \n",
       "285       rafael ainda nem nasceu e j√° escuta USERNAME #anjo #40semanas #EDeCasa   \n",
       "286            at√© que enfim um excelente programa de entrevistas na TV aberta üëç   \n",
       "287               master chef me da fome de madrugadato virando coruja sonambulo   \n",
       "\n",
       "                                                                                   tokens  \\\n",
       "283  [aparecer, o, √≠ndice, de, morte, o, meu, cidade, t√¥, muito, assustar, #BelemPedePaz]   \n",
       "284          [O, tchan, j√°, poder, substituir, o, moreno, pelar, bella, gil, #AltasHoras]   \n",
       "285   [rafael, ainda, nem, nascer, e, j√°, escutar, USERNAME, #anjo, #40semanas, #EDeCasa]   \n",
       "286         [at√©, que, enfim, um, excelente, programar, de, entrevisto, o, TV, aberto, üëç]   \n",
       "287              [master, chef, me, da, fome, de, madrugadato, virar, corujar, sonambulo]   \n",
       "\n",
       "                         features  \\\n",
       "283  [0, 2, 10, 0, 0, 0, 0, 0, 0]   \n",
       "284  [0, 0, 11, 0, 0, 0, 0, 0, 0]   \n",
       "285  [1, 0, 11, 0, 0, 0, 0, 0, 0]   \n",
       "286  [0, 0, 10, 2, 0, 0, 0, 0, 1]   \n",
       "287   [0, 1, 9, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                     pos_tag_features  \n",
       "283  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "284  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "285  [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "286  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "287  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Features for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from src.pipeline.resources import load_stopwords\n",
    "\n",
    "# Shift labels (-1, 0, 1) to the right (0, 1, 2) to comply with sklearn requirements.\n",
    "y_training = training.sentiment.apply(lambda x: int(x) + 1).to_numpy()\n",
    "y_test = test.sentiment.apply(lambda x: int(x) + 1).to_numpy()\n",
    "\n",
    "\n",
    "# Transform tokens into Bag of Words and then compute TF-IDF\n",
    "text_clf = Pipeline([\n",
    "    #('vect', CountVectorizer(lowercase=True, stop_words=stopwords.words('portuguese'))),\n",
    "    ('vect', HashingVectorizer(analyzer='word', ngram_range=(1, 1), n_features=5000, lowercase=True, stop_words=None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ]\n",
    ")\n",
    "X_training = text_clf.fit_transform(training.tokens.apply(lambda x: ' '.join(x))).toarray()\n",
    "X_test = text_clf.transform(test.tokens.apply(lambda x: ' '.join(x))).toarray()\n",
    "\n",
    "# Combine token based features with manually created features (e.g., pos tag, negations, and word polarity)\n",
    "feature_columns = ['features', 'pos_tag_features']\n",
    "features = [X_training] + [np.stack(training.features.to_list(), axis=0) for column in feature_columns]\n",
    "X_training = np.concatenate(features, axis=1)\n",
    "\n",
    "features = [X_test] + [np.stack(test.features.to_list(), axis=0) for column in feature_columns]\n",
    "X_test = np.concatenate(features, axis=1)\n",
    "\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12990, 5018)\n",
      "(2010, 5018)\n"
     ]
    }
   ],
   "source": [
    "print(X_training.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from src.utils import y_hat_to_sparse, y_to_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa4d41174414023826818f0252b592f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_parameters = {\n",
    "    'RF': {'n_estimators':200, 'criterion':'entropy', 'n_jobs':-1},\n",
    "    'LR': {'n_jobs': -1},\n",
    "    'LinearSVM': {'C':1.0, 'dual':False},\n",
    "    'PolinomialSVM': {'C':10.0, 'kernel': 'poly'},\n",
    "    'BernoulliNB': {'alpha':0.1},\n",
    "    'MLP': {'activation':'tanh', 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes':(200, 200)},\n",
    "    'DT': {'criterion': 'gini', 'max_depth': None},\n",
    "}\n",
    "\n",
    "models_to_train = {\n",
    "    'RF': RandomForestClassifier,\n",
    "    'LR': LogisticRegression,\n",
    "    'LinearSVM': LinearSVC,\n",
    "    'PolinomialSVM': SVC,\n",
    "    'BernoulliNB': BernoulliNB,\n",
    "    'MLP': MLPClassifier,\n",
    "    'DT': DecisionTreeClassifier,\n",
    "}\n",
    "\n",
    "trained_models = []\n",
    "test_scores = []\n",
    "\n",
    "for ix in tqdm(range(5)):\n",
    "\n",
    "    iteration_index = np.arange(X_training.shape[0])\n",
    "    np.random.shuffle(iteration_index)\n",
    "    \n",
    "    for model_name, model_class in models_to_train.items():\n",
    "        model = model_class(**models_parameters.get(model_name, {}))\n",
    "        model.fit(X_training[iteration_index], y_training[iteration_index])\n",
    "\n",
    "        trained_models.append((model_name, ix, model))\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        pred_labels = np.rint(preds)\n",
    "\n",
    "        sparse_y = y_to_sparse(y_test)\n",
    "        sparse_pred = y_hat_to_sparse(pred_labels)\n",
    "\n",
    "        eval_metric = metrics.f1_score(sparse_y, sparse_pred, average=None)\n",
    "        test_scores.append((model_name, ix, eval_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Individual Predictions</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>RawMetrics</th>\n",
       "      <th>F1-Neg</th>\n",
       "      <th>F1-Neu</th>\n",
       "      <th>F1-Pos</th>\n",
       "      <th>F1-Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6737012987012987, 0.486796785304248, 0.7480438184663538]</td>\n",
       "      <td>0.673701</td>\n",
       "      <td>0.486797</td>\n",
       "      <td>0.748044</td>\n",
       "      <td>0.636181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6573426573426574, 0.3910171730515192, 0.729589428975932]</td>\n",
       "      <td>0.657343</td>\n",
       "      <td>0.391017</td>\n",
       "      <td>0.729589</td>\n",
       "      <td>0.592650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6672268907563025, 0.49793388429752067, 0.7551020408163265]</td>\n",
       "      <td>0.667227</td>\n",
       "      <td>0.497934</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.640088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PolinomialSVM</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.45549132947976884, 0.1957585644371941, 0.6726986624704956]</td>\n",
       "      <td>0.455491</td>\n",
       "      <td>0.195759</td>\n",
       "      <td>0.672699</td>\n",
       "      <td>0.441316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6470092670598147, 0.4829600778967868, 0.7009966777408637]</td>\n",
       "      <td>0.647009</td>\n",
       "      <td>0.482960</td>\n",
       "      <td>0.700997</td>\n",
       "      <td>0.610322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6803069053708439, 0.5252725470763132, 0.7519042437431991]</td>\n",
       "      <td>0.680307</td>\n",
       "      <td>0.525273</td>\n",
       "      <td>0.751904</td>\n",
       "      <td>0.652495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5440677966101696, 0.41837732160312807, 0.6659328563566318]</td>\n",
       "      <td>0.544068</td>\n",
       "      <td>0.418377</td>\n",
       "      <td>0.665933</td>\n",
       "      <td>0.542793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6785137318255251, 0.4604486422668241, 0.7493540051679586]</td>\n",
       "      <td>0.678514</td>\n",
       "      <td>0.460449</td>\n",
       "      <td>0.749354</td>\n",
       "      <td>0.629439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6573426573426574, 0.3947368421052632, 0.7306238185255199]</td>\n",
       "      <td>0.657343</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.730624</td>\n",
       "      <td>0.594234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6677880571909167, 0.49896907216494846, 0.755507791509941]</td>\n",
       "      <td>0.667788</td>\n",
       "      <td>0.498969</td>\n",
       "      <td>0.755508</td>\n",
       "      <td>0.640755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algorithm  Iteration  \\\n",
       "0             RF          0   \n",
       "1             LR          0   \n",
       "2      LinearSVM          0   \n",
       "3  PolinomialSVM          0   \n",
       "4    BernoulliNB          0   \n",
       "5            MLP          0   \n",
       "6             DT          0   \n",
       "7             RF          1   \n",
       "8             LR          1   \n",
       "9      LinearSVM          1   \n",
       "\n",
       "                                                      RawMetrics    F1-Neg  \\\n",
       "0    [0.6737012987012987, 0.486796785304248, 0.7480438184663538]  0.673701   \n",
       "1    [0.6573426573426574, 0.3910171730515192, 0.729589428975932]  0.657343   \n",
       "2  [0.6672268907563025, 0.49793388429752067, 0.7551020408163265]  0.667227   \n",
       "3  [0.45549132947976884, 0.1957585644371941, 0.6726986624704956]  0.455491   \n",
       "4   [0.6470092670598147, 0.4829600778967868, 0.7009966777408637]  0.647009   \n",
       "5   [0.6803069053708439, 0.5252725470763132, 0.7519042437431991]  0.680307   \n",
       "6  [0.5440677966101696, 0.41837732160312807, 0.6659328563566318]  0.544068   \n",
       "7   [0.6785137318255251, 0.4604486422668241, 0.7493540051679586]  0.678514   \n",
       "8   [0.6573426573426574, 0.3947368421052632, 0.7306238185255199]  0.657343   \n",
       "9   [0.6677880571909167, 0.49896907216494846, 0.755507791509941]  0.667788   \n",
       "\n",
       "     F1-Neu    F1-Pos  F1-Measure  \n",
       "0  0.486797  0.748044    0.636181  \n",
       "1  0.391017  0.729589    0.592650  \n",
       "2  0.497934  0.755102    0.640088  \n",
       "3  0.195759  0.672699    0.441316  \n",
       "4  0.482960  0.700997    0.610322  \n",
       "5  0.525273  0.751904    0.652495  \n",
       "6  0.418377  0.665933    0.542793  \n",
       "7  0.460449  0.749354    0.629439  \n",
       "8  0.394737  0.730624    0.594234  \n",
       "9  0.498969  0.755508    0.640755  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Summarized Predictions</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">F1-Neg</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F1-Neu</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F1-Pos</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F1-Measure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.677840</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.488028</td>\n",
       "      <td>0.061362</td>\n",
       "      <td>0.762316</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.642728</td>\n",
       "      <td>0.017031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVM</th>\n",
       "      <td>0.667003</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.499071</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.755584</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.640553</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.479488</td>\n",
       "      <td>0.012040</td>\n",
       "      <td>0.750038</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.635978</td>\n",
       "      <td>0.003905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.647009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610322</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.657343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393249</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.730210</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.593601</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.549160</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.420688</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.665153</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.006294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolinomialSVM</th>\n",
       "      <td>0.455491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 F1-Neg              F1-Neu              F1-Pos            \\\n",
       "                   mean       std      mean       std      mean       std   \n",
       "Algorithm                                                                   \n",
       "MLP            0.677840  0.008584  0.488028  0.061362  0.762316  0.008613   \n",
       "LinearSVM      0.667003  0.000501  0.499071  0.000674  0.755584  0.000292   \n",
       "RF             0.678409  0.005909  0.479488  0.012040  0.750038  0.004971   \n",
       "BernoulliNB    0.647009  0.000000  0.482960  0.000000  0.700997  0.000000   \n",
       "LR             0.657343  0.000000  0.393249  0.002037  0.730210  0.000567   \n",
       "DT             0.549160  0.006384  0.420688  0.005373  0.665153  0.010627   \n",
       "PolinomialSVM  0.455491  0.000000  0.195759  0.000000  0.672699  0.000000   \n",
       "\n",
       "              F1-Measure            \n",
       "                    mean       std  \n",
       "Algorithm                           \n",
       "MLP             0.642728  0.017031  \n",
       "LinearSVM       0.640553  0.000265  \n",
       "RF              0.635978  0.003905  \n",
       "BernoulliNB     0.610322  0.000000  \n",
       "LR              0.593601  0.000868  \n",
       "DT              0.545000  0.006294  \n",
       "PolinomialSVM   0.441316  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_frame = pd.DataFrame(test_scores, columns=['Algorithm', 'Iteration', 'RawMetrics'])\n",
    "evaluation_f1_matrix = np.stack(evaluation_frame['RawMetrics'].to_list(), axis=0)\n",
    "evaluation_frame = pd.concat([evaluation_frame, pd.DataFrame(evaluation_f1_matrix, columns=['F1-Neg', 'F1-Neu', 'F1-Pos'])], axis=1)\n",
    "evaluation_frame['F1-Measure'] = np.mean(evaluation_f1_matrix, axis=1)\n",
    "\n",
    "display(HTML('<h3>Individual Predictions</h3>'))\n",
    "display(evaluation_frame.head(10))\n",
    "\n",
    "display(HTML('<h3>Summarized Predictions</h3>'))\n",
    "evaluation_summary_frame = (evaluation_frame\n",
    "                            [['Algorithm', 'F1-Neg', 'F1-Neu', 'F1-Pos', 'F1-Measure']]\n",
    "                            .groupby('Algorithm')\n",
    "                            .agg([np.mean, np.std])\n",
    "                           )\n",
    "display(evaluation_summary_frame.sort_values(by=('F1-Measure', 'mean'), ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
